# Conclusions and Future Work
### Addressing Battlegrounds
The Senate model was elucidating in explaining some factors in determining the results of a battleground district or state. As we addressed earlier, we find that correctly predicting regions that are prone to flipping is what distinguishes average and good models. The Senate model demonstrated the incredible predictive capacity of money in an election. The model, in contrast to the House model, really only leveraged campaign fundraising to pin the victors of politically precarious regions. The takeaway here is that candidate specific information would likely be more useful than district data for predicting regions that flip. If we were to reevaluate the House model we would definitely want to look at the amount of funds raised by each candidate. We would also experiment with other candidate-specific data like birthplace, relatives in political office, or education.

The Senate model, however, was not without its shortcomings. One of the challenges of predicting battleground races were the volatility in voter demographics. For example, Texas has been a republican stronghold for decades, but because there has been a large demographic change due to an influx of people from Latin America, old models based around incumbency and partisanship may not be as accurate anymore. This is a point of contention between our two models: in the House we found racial and ethnic demographics to be redundant, but in the Senate this hurt the effectiveness of our model.

Although a little trite, I believe the takeaway here is that there needs to be a balance between the predictors in our two models. Although it is hard to dig up candidate-specific data for district elections (House elections), we should include as much of it as possible. On the other hand, we should reevaluate the role of ethnic and racial demographics and voting models. Mechanisms like gerrymandering, backgrounded by a large climate of identity politics, asserts the obvious importance of race and ethnicity, however we did not derive any meaningful justifications here.

### House Model
Our model for predicting the House elections was passable. With a testing accuracy of around 80%, we found that we were able to provide reliable results for a majority of the districts. An obvious shortcoming of our model was that we weren’t incredibly effective at predicting “battleground” districts. This is what triggered the exploration of the Senate and the intricacies of swing-states.


### Senate Model
Our Senate model was quite effective,  around 92% accurate, notably predicting three challengers beating incumbents, and one open race but of course there is room for improvement. As stated before in the report, the main differentiator between good models  and the best models is the ability to accurately predict battleground districts. In this regard, there are many models that perform better than ours. We see that competing models for the midterm elections simply include more data. Future improvements to the model could be made by using campaign fundraising, incumbency etc. data along with models that use census data to predict how the actual population leans politically. For example, we could use income and education levels to predict how individuals will vote along with their likelihood to vote, and then use this to predict the vote count of a candidate. When incorporated with how much money the candidate spends and the incumbency factor, this could be a way to include the demographic changes.
