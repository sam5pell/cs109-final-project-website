# Conclusions and Future Work
The model we created was quite effective! We found that our model was *HERE* percent effective at predicting battleground districts. This is a byproduct of shifting focus away from general voter-district data and towards candidate and battleground specific data. There is, of course, room for improvement in our model. As specified throughout the report, the main differentiator between good and best models is the ability to accurately predict the battleground districts. In this regard we there are many models that perform better than ours.

How should we improve our model? We see that competing models for the midterm elections include: *other models and stats*. I believe in order to do so we would need to expand the data we have on candidates in battleground districts or consider different variations to our current model. For example, we could *look at x data* and we could use *some other model*. At a base level, we know that campaign funds are quite effective but do not get us to the same prediction accuracy of the some of the best models. Other models consider predictors like: *other predictors*.  These could also be useful for improving the accuracy of our model on battleground districts. I think the immediate next-steps would be: *fuck if i know*.

Working along this vectors of improvement would surely pave the way for a more predictive model.
